{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMO9TXtGteuISWwzSwlkyr3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomknightatl/USCCB/blob/main/Find_Adoration_and_Reconciliation_information_for_a_Parish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "3HnsXHCXv7Hc"
      },
      "outputs": [],
      "source": [
        "# Cell 1\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from urllib.parse import urljoin\n",
        "import sqlite3\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2\n",
        "def get_sitemap_urls(url):\n",
        "    try:\n",
        "        response = requests.get(urljoin(url, '/sitemap.xml'))\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'xml')\n",
        "            return [loc.text for loc in soup.find_all('loc')]\n",
        "    except:\n",
        "        pass\n",
        "    return []"
      ],
      "metadata": {
        "id": "37trhtN0v-m_"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3\n",
        "def search_for_keywords(url, keywords):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            text = soup.get_text().lower()\n",
        "            return any(keyword.lower() in text for keyword in keywords)\n",
        "    except:\n",
        "        pass\n",
        "    return False"
      ],
      "metadata": {
        "id": "-yIZ6S4gwAmg"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4\n",
        "def extract_time_info(url, keyword):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            text = soup.get_text()\n",
        "\n",
        "            # Look for patterns like \"X hours per week\" or \"X hours per month\"\n",
        "            time_pattern = re.compile(r'(\\d+)\\s*hours?\\s*per\\s*(week|month)', re.IGNORECASE)\n",
        "            match = time_pattern.search(text)\n",
        "\n",
        "            if match:\n",
        "                hours = int(match.group(1))\n",
        "                period = match.group(2).lower()\n",
        "                return f\"{hours} hours per {period}\"\n",
        "\n",
        "            # If no clear pattern is found, return the paragraph containing the keyword\n",
        "            paragraphs = soup.find_all('p')\n",
        "            for p in paragraphs:\n",
        "                if keyword.lower() in p.text.lower():\n",
        "                    return p.text.strip()\n",
        "    except:\n",
        "        pass\n",
        "    return \"Information not found\""
      ],
      "metadata": {
        "id": "dnQHSsYHwCLy"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 (Improved)\n",
        "def scrape_parish_data(url):\n",
        "    sitemap_urls = get_sitemap_urls(url)\n",
        "    all_urls = [url] + sitemap_urls\n",
        "\n",
        "    print(f\"Found {len(all_urls)} URLs on Sitemap page:\")\n",
        "    for sitemap_url in all_urls:\n",
        "        print(f\"Sitemap URL: {sitemap_url}\")\n",
        "\n",
        "        # Get all links from the sitemap page\n",
        "        try:\n",
        "            response = requests.get(sitemap_url)\n",
        "            if response.status_code == 200:\n",
        "                soup = BeautifulSoup(response.content, 'html.parser')\n",
        "                page_links = [a['href'] for a in soup.find_all('a', href=True)]\n",
        "            else:\n",
        "                page_links = []\n",
        "        except:\n",
        "            page_links = []\n",
        "\n",
        "        print(f\"Found {len(page_links)} links on {sitemap_url}\")\n",
        "\n",
        "        reconciliation_found = False\n",
        "        adoration_found = False\n",
        "        reconciliation_info = \"\"\n",
        "        adoration_info = \"\"\n",
        "        reconciliation_page = \"\"\n",
        "        adoration_page = \"\"\n",
        "\n",
        "        for page_url in [sitemap_url] + page_links:\n",
        "            print(f\"Checking {page_url}...\")\n",
        "\n",
        "            if not reconciliation_found and search_for_keywords(page_url, ['Reconciliation', 'Confession']):\n",
        "                reconciliation_found = True\n",
        "                reconciliation_info = extract_time_info(page_url, 'Reconciliation')\n",
        "                reconciliation_page = page_url\n",
        "                print(f\"Reconciliation information found on {page_url}\")\n",
        "\n",
        "            if not adoration_found and search_for_keywords(page_url, ['Adoration']):\n",
        "                adoration_found = True\n",
        "                adoration_info = extract_time_info(page_url, 'Adoration')\n",
        "                adoration_page = page_url\n",
        "                print(f\"Adoration information found on {page_url}\")\n",
        "\n",
        "            if reconciliation_found and adoration_found:\n",
        "                break\n",
        "\n",
        "        if reconciliation_found and adoration_found:\n",
        "            break\n",
        "\n",
        "    return {\n",
        "        'url': url,\n",
        "        'offers_reconciliation': reconciliation_found,\n",
        "        'reconciliation_info': reconciliation_info,\n",
        "        'reconciliation_page': reconciliation_page,\n",
        "        'offers_adoration': adoration_found,\n",
        "        'adoration_info': adoration_info,\n",
        "        'adoration_page': adoration_page\n",
        "    }"
      ],
      "metadata": {
        "id": "2dOwnZLGwGA8"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6\n",
        "parish_urls = [\n",
        "    'https://allsaintsdunwoody.org/',\n",
        "#    'https://sacredheartatlanta.org/',\n",
        "#    'https://cathedralctk.com/',\n",
        "    'https://www.christourhopeatl.org/'\n",
        "]\n",
        "\n",
        "results = []\n",
        "for url in parish_urls:\n",
        "    print(f\"Scraping {url}...\")\n",
        "    result = scrape_parish_data(url)\n",
        "    result['parish_name'] = url.split('//')[1].split('.')[0]\n",
        "    results.append(result)\n",
        "    print(f\"Completed scraping {url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miJEzRuawH0O",
        "outputId": "0423442e-eefb-426b-b0f5-195c4f91fef9"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping https://allsaintsdunwoody.org/...\n",
            "Found 9 URLs on Sitemap page:\n",
            "Sitemap URL: https://allsaintsdunwoody.org/\n",
            "Found 267 links on https://allsaintsdunwoody.org/\n",
            "Checking https://allsaintsdunwoody.org/...\n",
            "Reconciliation information found on https://allsaintsdunwoody.org/\n",
            "Adoration information found on https://allsaintsdunwoody.org/\n",
            "Completed scraping https://allsaintsdunwoody.org/\n",
            "Scraping https://www.christourhopeatl.org/...\n",
            "Found 1 URLs on Sitemap page:\n",
            "Sitemap URL: https://www.christourhopeatl.org/\n",
            "Found 0 links on https://www.christourhopeatl.org/\n",
            "Checking https://www.christourhopeatl.org/...\n",
            "Completed scraping https://www.christourhopeatl.org/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7\n",
        "df = pd.DataFrame(results)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW2v-B1zwJ78",
        "outputId": "9db5d569-e0f9-4c12-a9a2-666e1a529fd1"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 url  offers_reconciliation  \\\n",
            "0     https://allsaintsdunwoody.org/                   True   \n",
            "1  https://www.christourhopeatl.org/                  False   \n",
            "\n",
            "                                 reconciliation_info  \\\n",
            "0  Penance/Reconciliation\\nConfessions are heard ...   \n",
            "1                                                      \n",
            "\n",
            "              reconciliation_page  offers_adoration         adoration_info  \\\n",
            "0  https://allsaintsdunwoody.org/              True  Information not found   \n",
            "1                                             False                          \n",
            "\n",
            "                   adoration_page        parish_name  \n",
            "0  https://allsaintsdunwoody.org/  allsaintsdunwoody  \n",
            "1                                                www  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8\n",
        "conn = sqlite3.connect('parish_data.db')\n",
        "df.to_sql('parishes', conn, if_exists='replace', index=False)\n",
        "conn.close()\n",
        "\n",
        "print(\"Data saved to parish_data.db\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pWoW1iUwLqD",
        "outputId": "30151d24-e3d8-40de-a8d4-6e17bafc57c8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to parish_data.db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9\n",
        "# Verify data in the database\n",
        "conn = sqlite3.connect('parish_data.db')\n",
        "df_from_db = pd.read_sql_query(\"SELECT * FROM parishes\", conn)\n",
        "conn.close()\n",
        "\n",
        "print(df_from_db)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeKreCVPwNK_",
        "outputId": "80b26b1d-9715-4208-9f96-48442c444136"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 url  offers_reconciliation  \\\n",
            "0     https://allsaintsdunwoody.org/                      1   \n",
            "1  https://www.christourhopeatl.org/                      0   \n",
            "\n",
            "                                 reconciliation_info  \\\n",
            "0  Penance/Reconciliation\\nConfessions are heard ...   \n",
            "1                                                      \n",
            "\n",
            "              reconciliation_page  offers_adoration         adoration_info  \\\n",
            "0  https://allsaintsdunwoody.org/                 1  Information not found   \n",
            "1                                                 0                          \n",
            "\n",
            "                   adoration_page        parish_name  \n",
            "0  https://allsaintsdunwoody.org/  allsaintsdunwoody  \n",
            "1                                                www  \n"
          ]
        }
      ]
    }
  ]
}