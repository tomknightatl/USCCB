{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomknightatl/USCCB/blob/main/Find_Parish_Directory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXNwVrnLxqHJ"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install necessary libraries\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlite3\n",
        "import re\n",
        "import os\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Clone GitHub repository and configure Git\n",
        "\n",
        "# GitHub credentials\n",
        "GITHUB_REPO = 'USCCB'\n",
        "GITHUB_USERNAME = userdata.get('GitHubUserforUSCCB')\n",
        "GITHUB_PAT = userdata.get('GitHubPATforUSCCB')\n",
        "\n",
        "# GitHub repository URL\n",
        "REPO_URL = f\"https://{GITHUB_USERNAME}:{GITHUB_PAT}@github.com/{GITHUB_USERNAME}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# Check if the repository directory already exists\n",
        "if not os.path.exists(GITHUB_REPO):\n",
        "    # Clone the repository\n",
        "    !git clone {REPO_URL}\n",
        "    os.chdir(GITHUB_REPO)\n",
        "else:\n",
        "    print(f\"Repository {GITHUB_REPO} already exists. Updating...\")\n",
        "    os.chdir(GITHUB_REPO)\n",
        "    !git pull origin main\n",
        "\n",
        "# Configure Git\n",
        "!git config --global user.email \"tomk@github.leemail.me\"\n",
        "!git config --global user.name \"tomknightatl\""
      ],
      "metadata": {
        "id": "Ov3GGnLARDV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Fetch URLs from SQLite database and parse content\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('data.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Fetch first few URLs from the Dioceses table\n",
        "cursor.execute(\"SELECT Website FROM Dioceses LIMIT 3\")\n",
        "urls = [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "print(f\"Fetched {len(urls)} URLs from the database\")\n",
        "\n",
        "# Close the database connection\n",
        "conn.close()\n",
        "\n",
        "# List to store parsed content\n",
        "parsed_contents = []\n",
        "\n",
        "# Fetch and parse content for each URL\n",
        "# for url in urls:\n",
        "#     try:\n",
        "#         response = requests.get(url)\n",
        "#         soup = BeautifulSoup(response.content, 'html.parser')\n",
        "#         parsed_contents.append((url, soup))\n",
        "#         print(f\"Successfully fetched and parsed: {url}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error fetching or parsing {url}: {str(e)}\")\n",
        "#         parsed_contents.append((url, None))\n",
        "\n",
        "# print(f\"\\nProcessed {len(parsed_contents)} URLs\")"
      ],
      "metadata": {
        "id": "9xjtTXfgxwOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Improved function to find parish listing URL\n",
        "\n",
        "import re\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "def find_parish_url(soup, base_url):\n",
        "    # List of potential keywords and phrases\n",
        "    keywords = [\n",
        "        'parishes', 'parish', 'churches', 'locations', 'directory', 'find a parish',\n",
        "        'our parishes', 'parish finder', 'mass times', 'parish list',\n",
        "        'find a church', 'locator', 'parish search', 'map'\n",
        "    ]\n",
        "\n",
        "    # Function to check if a string contains any of the keywords\n",
        "    def contains_keyword(text):\n",
        "        return any(keyword in text.lower() for keyword in keywords)\n",
        "\n",
        "    # Search for links with matching text\n",
        "    for a in soup.find_all('a', href=True):\n",
        "        if contains_keyword(a.text):\n",
        "            return urljoin(base_url, a['href'])\n",
        "\n",
        "    # Search for links with matching href\n",
        "    for a in soup.find_all('a', href=True):\n",
        "        if contains_keyword(a['href']):\n",
        "            return urljoin(base_url, a['href'])\n",
        "\n",
        "    # Search for navigation menus\n",
        "    for nav in soup.find_all(['nav', 'ul', 'div'], class_=re.compile('(nav|menu)', re.I)):\n",
        "        for a in nav.find_all('a', href=True):\n",
        "            if contains_keyword(a.text) or contains_keyword(a['href']):\n",
        "                return urljoin(base_url, a['href'])\n",
        "\n",
        "    # Search for buttons\n",
        "    for button in soup.find_all(['button', 'a'], class_=re.compile('(btn|button)', re.I)):\n",
        "        if contains_keyword(button.text):\n",
        "            href = button.get('href')\n",
        "            if href:\n",
        "                return urljoin(base_url, href)\n",
        "\n",
        "    # If still not found, look for any link containing '/parish' or '/church'\n",
        "    for a in soup.find_all('a', href=re.compile('/(parish|church)', re.I)):\n",
        "        return urljoin(base_url, a['href'])\n",
        "\n",
        "    # If nothing found, return None\n",
        "    return None\n",
        "\n",
        "# Example usage:\n",
        "# parish_url = find_parish_url(soup, base_url)\n",
        "# if parish_url:\n",
        "#     print(f\"Found parish URL: {parish_url}\")\n",
        "# else:\n",
        "#     print(\"No parish URL found\")"
      ],
      "metadata": {
        "id": "B50-0qSsxyhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Iterate through URLs and find URLs for parish directories, maps, etc.\n",
        "\n",
        "conn = sqlite3.connect('data.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create table if not exists\n",
        "cursor.execute('''CREATE TABLE IF NOT EXISTS DiocesesParishDirectory\n",
        "                  (diocese TEXT, name TEXT, address TEXT, url TEXT)''')\n",
        "\n",
        "for url in urls:\n",
        "    print(f\"Processing: {url}\")\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        parish_url = find_parish_url(soup)\n",
        "        if parish_url:\n",
        "            if not parish_url.startswith('http'):\n",
        "                parish_url = url + parish_url if parish_url.startswith('/') else url + '/' + parish_url\n",
        "\n",
        "            parish_response = requests.get(parish_url)\n",
        "            parish_soup = BeautifulSoup(parish_response.content, 'html.parser')\n",
        "\n",
        "            parishes = parish_soup.find_all('div', class_=re.compile('parish'))\n",
        "\n",
        "            for parish in parishes:\n",
        "                name = parish.find('h2')\n",
        "                name = name.text.strip() if name else \"Name not found\"\n",
        "\n",
        "                address = parish.find('p', class_=re.compile('address'))\n",
        "                address = address.text.strip() if address else \"Address not found\"\n",
        "\n",
        "                parish_url = parish.find('a', href=re.compile('http'))\n",
        "                parish_url = parish_url['href'] if parish_url else \"URL not found\"\n",
        "\n",
        "                cursor.execute(\"INSERT INTO parishes VALUES (?, ?, ?, ?)\", (url, name, address, parish_url))\n",
        "\n",
        "            print(f\"Processed {len(parishes)} parishes for {url}\")\n",
        "        else:\n",
        "            print(f\"No parish listing found for {url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {url}: {str(e)}\")\n",
        "\n",
        "conn.commit()\n",
        "conn.close()\n",
        "print(\"\\nDatabase connection closed\")"
      ],
      "metadata": {
        "id": "kMcje622x0Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Verify the data in the SQLite database\n",
        "\n",
        "conn = sqlite3.connect('data.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"SELECT * FROM DiocesesParishDirectory LIMIT 5\")\n",
        "rows = cursor.fetchall()\n",
        "for row in rows:\n",
        "    print(row)\n",
        "\n",
        "conn.close()\n",
        "print(\"\\nDatabase connection closed\")"
      ],
      "metadata": {
        "id": "rrzgbzPpx1VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Commit changes and push to GitHub\n",
        "# Add changes to git\n",
        "!git add data.db\n",
        "\n",
        "# Commit changes\n",
        "!git commit -m \"Updated parishes data for multiple dioceses\"\n",
        "\n",
        "# Push changes to GitHub\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "huelyWkgRQFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}