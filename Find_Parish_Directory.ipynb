{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomknightatl/USCCB/blob/main/Find_Parish_Directory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXNwVrnLxqHJ"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install necessary libraries\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import sqlite3\n",
        "import re\n",
        "import os\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Clone GitHub repository and configure Git\n",
        "\n",
        "# GitHub credentials\n",
        "GITHUB_REPO = 'USCCB'\n",
        "GITHUB_USERNAME = userdata.get('GitHubUserforUSCCB')\n",
        "GITHUB_PAT = userdata.get('GitHubPATforUSCCB')\n",
        "\n",
        "# GitHub repository URL\n",
        "REPO_URL = f\"https://{GITHUB_USERNAME}:{GITHUB_PAT}@github.com/{GITHUB_USERNAME}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# Check if the repository directory already exists\n",
        "if not os.path.exists(GITHUB_REPO):\n",
        "    # Clone the repository\n",
        "    !git clone {REPO_URL}\n",
        "    os.chdir(GITHUB_REPO)\n",
        "else:\n",
        "    print(f\"Repository {GITHUB_REPO} already exists. Updating...\")\n",
        "    os.chdir(GITHUB_REPO)\n",
        "    !git pull origin main\n",
        "\n",
        "# Configure Git\n",
        "!git config --global user.email \"tomk@github.leemail.me\"\n",
        "!git config --global user.name \"tomknightatl\""
      ],
      "metadata": {
        "id": "Ov3GGnLARDV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Fetch URLs from SQLite database for dioceses without parish directory URLs\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('data.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# SQL query to join Dioceses and DiocesesParishDirectory tables\n",
        "# and select dioceses without parish directory URLs\n",
        "query = \"\"\"\n",
        "SELECT d.Website\n",
        "FROM Dioceses d\n",
        "LEFT JOIN DiocesesParishDirectory dpd ON d.Website = dpd.diocese_url\n",
        "WHERE dpd.parish_directory_url IS NULL OR dpd.parish_directory_url = ''\n",
        "\"\"\"\n",
        "\n",
        "cursor.execute(query)\n",
        "urls = [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "print(f\"Fetched {len(urls)} URLs from the database for dioceses without parish directory URLs\")\n",
        "\n",
        "# Close the database connection\n",
        "conn.close()\n",
        "\n",
        "# List to store parsed content\n",
        "parsed_contents = []\n",
        "\n",
        "# Fetch and parse content for each URL\n",
        "# (Commented out to prevent actual web requests during demonstration)\n",
        "# for url in urls:\n",
        "#     try:\n",
        "#         response = requests.get(url)\n",
        "#         soup = BeautifulSoup(response.content, 'html.parser')\n",
        "#         parsed_contents.append((url, soup))\n",
        "#         print(f\"Successfully fetched and parsed: {url}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error fetching or parsing {url}: {str(e)}\")\n",
        "#         parsed_contents.append((url, None))\n",
        "\n",
        "# print(f\"\\nProcessed {len(parsed_contents)} URLs\")"
      ],
      "metadata": {
        "id": "9xjtTXfgxwOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Improved function to find parish listing URL with multiple link names\n",
        "\n",
        "from urllib.parse import urljoin\n",
        "import re\n",
        "\n",
        "def find_parish_url(soup, base_url):\n",
        "    # List of possible link names for parish directories\n",
        "    parish_link_names = ['Churches', 'Directory of Parishes', 'Parishes', 'parishfinder', 'Parish Finder', 'Find a Parish', 'Locations']\n",
        "\n",
        "    # Look for links with exact matches to the names in our list\n",
        "    for name in parish_link_names:\n",
        "        link = soup.find('a', string=lambda text: text and text.strip() == name)\n",
        "        if link and 'href' in link.attrs:\n",
        "            return urljoin(base_url, link['href'])\n",
        "\n",
        "    # If exact match not found, look for partial matches in link text\n",
        "    all_links = soup.find_all('a', href=True)\n",
        "    for link in all_links:\n",
        "        if any(name.lower() in link.text.lower() for name in parish_link_names):\n",
        "            return urljoin(base_url, link['href'])\n",
        "\n",
        "    # If still not found, look in navigation menus\n",
        "    nav_menus = soup.find_all(['nav', 'ul', 'div'], class_=lambda x: x and 'nav' in x.lower())\n",
        "    for menu in nav_menus:\n",
        "        for name in parish_link_names:\n",
        "            link = menu.find('a', string=lambda text: text and name.lower() in text.lower())\n",
        "            if link and 'href' in link.attrs:\n",
        "                return urljoin(base_url, link['href'])\n",
        "\n",
        "    # If nothing found, return None\n",
        "    return None\n",
        "\n",
        "# Example usage:\n",
        "# url = \"https://www.stpeterdiocese.org/\"\n",
        "# response = requests.get(url)\n",
        "# soup = BeautifulSoup(response.content, 'html.parser')\n",
        "# parish_url = find_parish_url(soup, url)\n",
        "# if parish_url:\n",
        "#     print(f\"Found parish directory URL: {parish_url}\")\n",
        "# else:\n",
        "#     print(\"No parish directory URL found\")"
      ],
      "metadata": {
        "id": "B50-0qSsxyhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is temporary code to drop the table if it exists.  Only needed until the table data structure is finalized.\n",
        "import sqlite3\n",
        "\n",
        "# Connect to the SQLite3 database\n",
        "# Replace 'your_database.db' with the path to your database file\n",
        "connection = sqlite3.connect('data.db')\n",
        "\n",
        "try:\n",
        "    # Create a cursor object using the connection\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # SQL command to drop the table\n",
        "    drop_table_query = \"DROP TABLE IF EXISTS DiocesesParishDirectory;\"\n",
        "\n",
        "    # Execute the SQL command\n",
        "    cursor.execute(drop_table_query)\n",
        "\n",
        "    # Commit the changes\n",
        "    connection.commit()\n",
        "\n",
        "    print(\"Table DiocesesParishDirectory deleted successfully.\")\n",
        "\n",
        "except sqlite3.Error as error:\n",
        "    print(f\"Error while deleting table: {error}\")\n",
        "\n",
        "finally:\n",
        "    # Close the connection\n",
        "    if connection:\n",
        "        connection.close()"
      ],
      "metadata": {
        "id": "2gPE5Gsokvgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Write the results to the database.\n",
        "\n",
        "conn = sqlite3.connect('data.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create table if not exists\n",
        "cursor.execute('''CREATE TABLE IF NOT EXISTS DiocesesParishDirectory\n",
        "                  (diocese_url TEXT, parish_directory_url TEXT, found TEXT)''')\n",
        "\n",
        "for url in urls:\n",
        "    print(f\"Processing: {url}\")\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        parish_directory_url = find_parish_url(soup, url)\n",
        "\n",
        "        if parish_directory_url:\n",
        "            print(f\"Found parish directory URL: {parish_directory_url}\")\n",
        "            cursor.execute(\"INSERT OR REPLACE INTO DiocesesParishDirectory VALUES (?, ?, ?)\",\n",
        "                           (url, parish_directory_url, \"Success\"))\n",
        "\n",
        "        else:\n",
        "            print(f\"No parish directory URL found for {url}\")\n",
        "            # Log the unsuccessful attempt in the database\n",
        "            cursor.execute(\"INSERT OR REPLACE INTO DiocesesParishDirectory VALUES (?, ?, ?)\",\n",
        "                           (url, None, f\"No parish directory URL found for {url}\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {url}: {str(e)}\")\n",
        "\n",
        "conn.commit()\n",
        "conn.close()\n",
        "print(\"\\nDatabase connection closed\")"
      ],
      "metadata": {
        "id": "kMcje622x0Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Verify the data in the SQLite database\n",
        "\n",
        "conn = sqlite3.connect('data.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"SELECT * FROM DiocesesParishDirectory LIMIT 5\")\n",
        "rows = cursor.fetchall()\n",
        "for row in rows:\n",
        "    print(row)\n",
        "\n",
        "conn.close()\n",
        "print(\"\\nDatabase connection closed\")"
      ],
      "metadata": {
        "id": "rrzgbzPpx1VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Commit changes and push to GitHub\n",
        "# Add changes to git\n",
        "!git add data.db\n",
        "\n",
        "# Commit changes\n",
        "!git commit -m \"Updated Parish Directory URLs for multiple dioceses in Find_Parish_Directory.ipynb\"\n",
        "\n",
        "# Push changes to GitHub\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "huelyWkgRQFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}