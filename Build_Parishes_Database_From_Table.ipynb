{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfY/kZJx3LekEzDAvQEg4T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomknightatl/USCCB/blob/main/Build_Parishes_Database_From_Table.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIm-qDFgrqK3"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Import required libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import os\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Clone GitHub repository and configure Git\n",
        "\n",
        "\n",
        "# GitHub credentials\n",
        "GITHUB_REPO = 'USCCB'\n",
        "GITHUB_USERNAME = userdata.get('GitHubUserforUSCCB')\n",
        "GITHUB_PAT = userdata.get('GitHubPATforUSCCB')\n",
        "\n",
        "# GitHub repository URL\n",
        "REPO_URL = f\"https://{GITHUB_USERNAME}:{GITHUB_PAT}@github.com/{GITHUB_USERNAME}/{GITHUB_REPO}.git\"\n",
        "\n",
        "# Check if the repository directory already exists\n",
        "if not os.path.exists(GITHUB_REPO):\n",
        "    # Clone the repository\n",
        "    !git clone {REPO_URL}\n",
        "    os.chdir(GITHUB_REPO)\n",
        "else:\n",
        "    print(f\"Repository {GITHUB_REPO} already exists. Updating...\")\n",
        "    os.chdir(GITHUB_REPO)\n",
        "    !git pull origin main\n",
        "\n",
        "# Configure Git\n",
        "!git config --global user.email \"tomk@github.leemail.me\"\n",
        "!git config --global user.name \"tomknightatl\""
      ],
      "metadata": {
        "id": "DoThd3d7RtRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Retrieve URLs from the database\n",
        "conn = sqlite3.connect('data.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Fetch non-null parish directory URLs.  Note this is temporarily limited to 3 records, for testing.\n",
        "cursor.execute(\"SELECT parish_directory_url FROM DiocesesParishDirectory WHERE parish_directory_url IS NOT NULL LIMIT 3\")\n",
        "urls = cursor.fetchall()\n"
      ],
      "metadata": {
        "id": "KIVTfVlOrtIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Process each URL\n",
        "for url in urls:\n",
        "    url = url[0]  # Extract URL from tuple\n",
        "    print(f\"Processing URL: {url}\")\n",
        "\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Find the table (adjust the selector if needed)\n",
        "    table = soup.find('table', {'id': 'table_1'})\n",
        "\n",
        "    if table:\n",
        "        rows = table.find_all('tr')\n",
        "\n",
        "        data = []\n",
        "        for row in rows[1:]:  # Skip the header row\n",
        "            cols = row.find_all('td')\n",
        "            row_data = [col.text.strip() for col in cols[:-1]]  # Extract all columns except the last one\n",
        "\n",
        "            # Extract the hyperlink from the last column\n",
        "            web_col = cols[-1]\n",
        "            link = web_col.find('a')\n",
        "            if link:\n",
        "                row_data.append(link.get('href'))\n",
        "            else:\n",
        "                row_data.append('')\n",
        "\n",
        "            data.append(row_data)\n",
        "\n",
        "        # Create a DataFrame\n",
        "        columns = ['Name', 'Status', 'Deanery', 'EST', 'Street Address', 'City', 'State', 'Zipcode', 'Phone Number', 'Web']\n",
        "        df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "        # Store the data in the database\n",
        "        table_name = f\"parishes_{url.split('/')[-2]}\"  # Create a unique table name based on the URL\n",
        "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "        print(f\"Data stored in table: {table_name}\")\n",
        "    else:\n",
        "        print(f\"No table found for URL: {url}\")"
      ],
      "metadata": {
        "id": "xlQd-ThXruqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Commit changes and push to GitHub\n",
        "# Add changes to git\n",
        "!git add data.db\n",
        "\n",
        "# Commit changes\n",
        "!git commit -m \"Added data to  data.db using Build_Parishes_Database_From_Table.ipynb\"\n",
        "\n",
        "# Push changes to GitHub\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "5do6Glw0R9A9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}